{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim, logging, nltk, re, os, sys\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from gensim.models import Phrases\n",
    "import googlemaps\n",
    "import requests\n",
    "import dateparser\n",
    "from dateparser.search import search_dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geoparsing\n",
    "This is based on GoogleMaps API, and uses Python2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def geoParse(query):\n",
    "    gmaps = googlemaps.Client(key='AIzaSyACekuOv6hyB5o2dQq1mpP0Bztjx0vjTuM')\n",
    "    geocode_result = gmaps.geocode(query)\n",
    "    return {'bounds': geocode_result[0]['geometry']['bounds'], 'string': geocode_result[0]['formatted_address']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bounds': {u'northeast': {u'lat': 48.7297227, u'lng': -122.4090338}, u'southwest': {u'lat': 48.717229, u'lng': -122.416576}}, 'string': u'SST, Bellingham, WA 98229, USA'}\n"
     ]
    }
   ],
   "source": [
    "print geoParse('sst pacific ocean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal parsing\n",
    "This is based on dateparser library. Internally, it is a name entity recogonition (NER) process. In this case, dateparser uses a pre-built time detection NLP model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def temporalParse(query):\n",
    "    return search_dates(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-26 14:30:59.663437\n"
     ]
    }
   ],
   "source": [
    "print dateparser.parse('1 hour ago')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'in March 3rd, 2004', datetime.datetime(2004, 3, 3, 0, 0))]\n"
     ]
    }
   ],
   "source": [
    "print search_dates(\"ocean wind in March 3rd, 2004\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic analysis\n",
    "This is based on MUDROD, a previous NASA funded project (https://github.com/apache/incubator-sdap-mudrod). Internally, it is based on a collaborative filtering algorithm training with user behavior and metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "baseUrl = \"http://199.26.254.151:8080/mudrod-service/SearchVocab?concept=\"\n",
    "\n",
    "def expandQuery(query):\n",
    "    url = baseUrl + query\n",
    "    response = requests.get(url)    \n",
    "    dic = response.json()\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'graph': {u'ontology': [{u'word': u'sea surface temperature', u'weight': 1.0}, {u'word': u'ocean temperature', u'weight': 1.0}, {u'word': u'group high resolution sea surface temperature dataset', u'weight': 0.89}, {u'word': u'ghrsst', u'weight': 0.87}, {u'word': u'surface temperature', u'weight': 0.78}, {u'word': u'l2p', u'weight': 0.78}, {u'word': u'sea surface temperature monthly', u'weight': 0.72}, {u'word': u'l4', u'weight': 0.68}, {u'word': u'caspian sea', u'weight': 0.68}, {u'word': u'aqua', u'weight': 0.62}]}}\n"
     ]
    }
   ],
   "source": [
    "print expandQuery('sst')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phrase detection\n",
    "This is based on the co-occurance matrix computed by genism. This bigram and trigram models are training with PO.DAAC metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def phraseDetect(query):\n",
    "    bigram = Phrases.load('model/bigram')\n",
    "    trigram = Phrases.load('model/trigram')\n",
    "    return trigram[bigram[query.split()]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'modis', u'level_2', u'sea_surface_temperature']\n"
     ]
    }
   ],
   "source": [
    "print phraseDetect('modis level 2 sea surface temperature')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting all this together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deepQuery(query):\n",
    "    res= {}\n",
    "    \n",
    "    #temporal parsing\n",
    "    res['time'] = temporalParse(query)\n",
    "    query = query.replace(str(res['time'][0][0]), '')\n",
    "    \n",
    "    #geoparsing\n",
    "    geo = geoParse(query)\n",
    "    res['geo'] = geo['bounds']\n",
    "    query = query.replace(str(geo['string']).lower(), '')\n",
    "    \n",
    "    #query expansion\n",
    "    res['phrase'] = phraseDetect(query.strip())\n",
    "    \n",
    "    #semantic expansion, just to expand the first phrase as an example\n",
    "    phrase = str(res['phrase'][0])\n",
    "    res['semantics'] = expandQuery(phrase.replace('_', ' '))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'phrase': [u'sea_surface_temperature', u'modis', u'level_2'], 'geo': {u'northeast': {u'lat': 59.48222930000001, u'lng': -66.51908139999999}, u'southwest': {u'lat': -77.8225785, u'lng': 128.576489}}, 'semantics': {u'graph': {u'ontology': [{u'word': u'sst', u'weight': 1.0}, {u'word': u'ocean temperature', u'weight': 1.0}, {u'word': u'ghrsst', u'weight': 1.0}, {u'word': u'group high resolution sea surface temperature dataset', u'weight': 0.97}, {u'word': u'reynolds sea surface temperature', u'weight': 0.83}, {u'word': u'surface temperature', u'weight': 0.82}, {u'word': u'mur', u'weight': 0.81}, {u'word': u'caspian sea', u'weight': 0.81}, {u'word': u'sea surface temperature el nino', u'weight': 0.76}, {u'word': u'ocean tempetature', u'weight': 0.76}]}}, 'time': [(u'in March 3rd, 2004', datetime.datetime(2004, 3, 3, 0, 0))]}\n"
     ]
    }
   ],
   "source": [
    "testQ = 'sea surface temperature modis level 2 pacific ocean in March 3rd, 2004'\n",
    "print(deepQuery(testQ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
